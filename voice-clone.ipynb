{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#step1 - audio file to test conversion\n",
        "\n",
        "!pip install speechRecognition"
      ],
      "metadata": {
        "id": "QGVToht_JXdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as spr"
      ],
      "metadata": {
        "id": "o4pUqlWuJZya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recognizer=spr.Recognizer()"
      ],
      "metadata": {
        "id": "g8xIUf5vJe_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kindly upload the desired audio file that has to be converted\n",
        "\n",
        "proverb1=spr.AudioFile('/content/recording2023-10-05-23-59-23.wav') #the input audio file"
      ],
      "metadata": {
        "id": "V1es3ZwoJh_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with proverb1 as source:\n",
        "  proverb1 = recognizer.record(source,duration=120,offset=11)"
      ],
      "metadata": {
        "id": "q4lGx1ydJjlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the language spoken in the audio in text --> language\n",
        "text = recognizer.recognize_google(proverb1, language=\"ta-IN\")\n",
        "print(text)"
      ],
      "metadata": {
        "id": "5sEBKwQCJl8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('writeme.txt', 'w') as file:\n",
        "    file.write(text)"
      ],
      "metadata": {
        "id": "VGnLqArz9XMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2 --> translation\n",
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "poRPZct6JpxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "file_translate = Translator()"
      ],
      "metadata": {
        "id": "4V4OAOa2Jrru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = file_translate.translate(text)\n",
        "print(result.text)"
      ],
      "metadata": {
        "id": "-xNiJIKWJuFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('speech.txt', 'w') as file:\n",
        "    file.write(result.text)"
      ],
      "metadata": {
        "id": "_eNgGccnJvmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCxF9oU3Aa6r"
      },
      "outputs": [],
      "source": [
        "#step3 --> text to audio conversion\n",
        "\n",
        "!pip3 install -U scipy\n",
        "\n",
        "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
        "%cd tortoise-tts\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install transformers==4.19.0 einops==0.5.0 rotary_embedding_torch==0.1.5 unidecode==1.3.5\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()"
      ],
      "metadata": {
        "id": "ojs1qIggAnkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we split the text into smaller forms so that the audio can be easily generated.\n",
        "with open('/content/speech.txt', 'r') as f:\n",
        "   lines = f.read().split('.')\n",
        "\n",
        "# **** NOTE *****\n",
        "\n",
        "# If you have GPU inbuilt in your system you can skip the above code and below cells and run the following code given below\n",
        "\n",
        "# Optionally, upload use your own voice by running the next two cells. I recommend\n",
        "# you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
        "\n",
        "CUSTOM_VOICE_NAME = \"speech1\"\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "os.makedirs(custom_voice_folder)\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "  with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "    f.write(file_data)\n",
        "\n",
        "from tortoise.utils.text import split_and_recombine_text\n",
        "from time import time\n",
        "import os\n",
        "\n",
        "outpath = \"results/longform/\"\n",
        "\n",
        "textfile_path = \"../speech.txt\"\n",
        "\n",
        "# Process text\n",
        "with open(textfile_path, 'r', encoding='utf-8') as f:\n",
        "    text = ' '.join([l for l in f.readlines()])\n",
        "    if '|' in text:\n",
        "        print(\"Found the '|' character in your text, which I will use as a cue for where to split it up. If this was not\"\n",
        "              \"your intent, please remove all '|' characters from the input.\")\n",
        "        texts = text.split('|')\n",
        "    else:\n",
        "        texts = split_and_recombine_text(text)\n",
        "\n",
        "seed = int(time())\n",
        "\n",
        "voice_outpath = os.path.join(outpath, CUSTOM_VOICE_NAME)\n",
        "os.makedirs(voice_outpath, exist_ok=True)\n",
        "\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "\n",
        "all_parts = []\n",
        "for j, text in enumerate(texts):\n",
        "    gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                              preset=\"standard\", k=1, use_deterministic_seed=seed)\n",
        "    gen = gen.squeeze(0).cpu()\n",
        "    torchaudio.save(os.path.join(voice_outpath, f'{j}.wav'), gen, 24000)\n",
        "    all_parts.append(gen)\n",
        "\n",
        "full_audio = torch.cat(all_parts, dim=-1)\n",
        "torchaudio.save(os.path.join(voice_outpath, 'combined.wav'), full_audio, 24000)\n",
        "IPython.display.Audio(os.path.join(voice_outpath, 'combined.wav'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LVHmoCIAzGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=len(lines)\n",
        "di={}\n",
        "for i in range(1,n):\n",
        "  di[i]=lines[i]"
      ],
      "metadata": {
        "id": "RbPcjhyuA4re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from torchaudio.utils import download_asset\n",
        "\n",
        "#\n",
        "\n",
        "# This is the text that will be spoken.\n",
        "#\"I told him that he went to north according to the Guru's wish and he went to China. As soon as heads there, a disciple of the Buddha or someone immersed in his path would come this way. The news spread that MS had this desire all his life.\"\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "\n",
        "preset = \"high_quality\" # I have chosen \"high_quality\"\n",
        "\n",
        "# upload at least 2 sample audios. They must be a WAV file, 6-10 seconds long.\n",
        "\n",
        "for k in di.keys():\n",
        "  CUSTOM_VOICE_NAME=\"audio{fname}\".format(fname = k)\n",
        "  text=di[k]\n",
        "  custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "  os.makedirs(custom_voice_folder)\n",
        "  for i, file_data in enumerate(files.upload().values()):\n",
        "    with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "      f.write(file_data)\n",
        "  voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "  gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "  torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 24000)\n",
        "  torchaudio.save('/content/'+f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 24000)\n",
        "  IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')\n"
      ],
      "metadata": {
        "id": "46_XKqTcA_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the previous code has run, upload all your saved recordings to combine them into a single folder.\n",
        "\n",
        "from pydub import AudioSegment\n",
        "sound1 = AudioSegment.from_file(\"/path/to/sound.wav\", format=\"wav\")\n",
        "sound2 = AudioSegment.from_file(\"/path/to/another_sound.wav\", format=\"wav\")\n",
        "sound3 = AudioSegment.from_file(\"/path/to/another_sound.wav\", format=\"wav\")\n",
        "sound4 = AudioSegment.from_file(\"/path/to/another_sound.wav\", format=\"wav\")\n",
        "sound5 = AudioSegment.from_file(\"/path/to/another_sound.wav\", format=\"wav\")\n",
        "\n",
        "# sound1 6 dB louder\n",
        "louder = sound1 + 6\n",
        "\n",
        "\n",
        "# sound1, with sound2 appended (use louder instead of sound1 to append the louder version)\n",
        "combined = sound1 + sound2 + sound3 + sound4 + sound5 + etc...\n",
        "\n",
        "# simple export\n",
        "file_handle = combined.export(\"/path/to/output.mp3\", format=\"mp3\")"
      ],
      "metadata": {
        "id": "m3FSTZSZ9xWW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}